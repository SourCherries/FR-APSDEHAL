{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FR_APSDEHAL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPln23bir3EhIiTg3eEf9OW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SourCherries/FR-APSDEHAL/blob/master/FR_APSDEHAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face recognition CNN by APSDEHAL from"
      ],
      "metadata": {
        "id": "PxBsVKqgmnbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimal script to run forward pass on model using initial parameters. Uncertain whether initial paramters are random. Goal is to pinpoint source of error when running main.py where weights appear to be on cpu despite putting entire model onto gpu."
      ],
      "metadata": {
        "id": "dkOCYletrwQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on [pytorch example](https://pytorch.org/hub/pytorch_vision_vgg/) and on [CNN by APSDEHAL](https://github.com/apsdehal/Face-Recognition)."
      ],
      "metadata": {
        "id": "KmfTccA7rzoF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9TP-1-M9me_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65185c35-a6f1-49d8-c113-70ddec490fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FR-APSDEHAL'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 112 (delta 27), reused 0 (delta 0), pack-reused 64\u001b[K\n",
            "Receiving objects: 100% (112/112), 207.43 KiB | 687.00 KiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SourCherries/FR-APSDEHAL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_model = \"cuda\"\n",
        "device_input = \"cuda\""
      ],
      "metadata": {
        "id": "XWRaPDieMWRO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(1, '/content/FR-APSDEHAL')\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "# from model_noargs import Network\n",
        "from model_modlist import Network\n",
        "from constants import IMG_SIZE, NUM_CHANNELS\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "G7UHkGnsr4tw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load image(s)"
      ],
      "metadata": {
        "id": "DkL7MZFN8YoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# judi = read_image(\"/content/FR-APSDEHAL/judi-dench-256.png\")\n",
        "# kathy = read_image(\"/content/FR-APSDEHAL/kathleen-turner-256.png\")\n",
        "# input_batch = torch.cat([torch.unsqueeze(judi, 0), torch.unsqueeze(kathy, 0)], dim=0)\n",
        "\n",
        "# print(input_batch.shape)\n",
        "# print(input_batch.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78moiD6J8bVK",
        "outputId": "751ccb6f-0699-4db7-f301-ae96f3baab07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 256, 256])\n",
            "torch.uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "judi = Image.open(\"/content/FR-APSDEHAL/judi-dench-256.png\")\n",
        "kathy = Image.open(\"/content/FR-APSDEHAL/kathleen-turner-256.png\")\n",
        "input_tensor = torch.cat([torch.unsqueeze(preprocess(judi), 0), torch.unsqueeze(preprocess(kathy), 0)], dim=0)\n",
        "input_tensor.shape"
      ],
      "metadata": {
        "id": "ecx3msaaVFMM",
        "outputId": "800720c8-1479-472a-886b-6b3b4d2888f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# input_image = Image.open(\"/content/FR-APSDEHAL/judi-dench-256.png\")\n",
        "# input_tensor = preprocess(input_image)\n",
        "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "input_batch = input_tensor\n",
        "input_batch = input_batch.to(device_input)\n",
        "\n",
        "print(input_batch.shape)\n",
        "print(input_batch.dtype)\n",
        "print(input_batch.min())\n",
        "print(input_batch.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052El6qB_CzR",
        "outputId": "89349ac6-24ca-4682-be92-889773e82e82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 256, 256])\n",
            "torch.float32\n",
            "tensor(-2.1179, device='cuda:0')\n",
            "tensor(2.4286, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model"
      ],
      "metadata": {
        "id": "oCGLFp6P8cVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network().to(device_model)\n",
        "# model = Network()\n",
        "# model = model.to(device_model)\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJzKJe3i6JIU",
        "outputId": "b25766b4-d3a2-4e42-d1d8-82b70747c07d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 64, 58, 58])\n",
            "torch.Size([2, 215296])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/FR-APSDEHAL/model_modlist.py:63: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return nn.functional.log_softmax(self.fully_connected2(x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output.dtype)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "i-NoaITVDi_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMnPlvpGDxKn",
        "outputId": "c948bc9c-8e66-403b-a329-6128671138ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0672, 0.0653, 0.0660, 0.0661, 0.0653, 0.0665, 0.0654, 0.0676, 0.0686,\n",
            "        0.0692, 0.0676, 0.0688, 0.0657, 0.0645, 0.0662], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.conv_output_size"
      ],
      "metadata": {
        "id": "Ht8u2WyRUnr8",
        "outputId": "c8d4f7b6-6ef3-49e5-c1e1-3f0c57316e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215296"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}