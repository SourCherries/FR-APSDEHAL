{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FR_APSDEHAL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsTUJJtAmGbEw0WtzAGk63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SourCherries/FR-APSDEHAL/blob/master/FR_APSDEHAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face recognition CNN by APSDEHAL from"
      ],
      "metadata": {
        "id": "PxBsVKqgmnbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimal script to run forward pass on model using initial parameters. Uncertain whether initial paramters are random. Goal is to pinpoint source of error when running main.py where weights appear to be on cpu despite putting entire model onto gpu."
      ],
      "metadata": {
        "id": "dkOCYletrwQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on [pytorch example](https://pytorch.org/hub/pytorch_vision_vgg/) and on [CNN by APSDEHAL](https://github.com/apsdehal/Face-Recognition).**bold text**"
      ],
      "metadata": {
        "id": "KmfTccA7rzoF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9TP-1-M9me_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb818804-db7a-44db-dac8-3a0f16ebc747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FR-APSDEHAL'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 76 (delta 5), reused 0 (delta 0), pack-reused 64\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SourCherries/FR-APSDEHAL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(1, '/content/FR-APSDEHAL')\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from model_noargs import Network"
      ],
      "metadata": {
        "id": "G7UHkGnsr4tw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network()"
      ],
      "metadata": {
        "id": "3OckLjSCr612"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}